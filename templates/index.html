<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NEXUS 3000 â€¢ COSMIC AGI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Courier New', monospace;
            background: #000;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            color: #00ffff;
            overflow: hidden;
            position: relative;
        }
        script { display: none !important; }
        
        #start-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.95);
            display: flex;
            align-items: center;
            justify-content: center;
            z-index: 9999;
            backdrop-filter: blur(10px);
            cursor: pointer;
            transition: opacity 0.5s ease;
        }
        #start-button {
            font-family: 'Courier New', monospace;
            font-size: 1.8em;
            color: #00ffff;
            background: linear-gradient(45deg, rgba(0, 255, 255, 0.1), rgba(255, 0, 255, 0.1));
            border: 3px solid #00ffff;
            padding: 25px 50px;
            border-radius: 15px;
            cursor: pointer;
            text-shadow: 0 0 20px #00ffff;
            box-shadow: 0 0 40px rgba(0, 255, 255, 0.5), inset 0 0 20px rgba(0, 255, 255, 0.1);
            animation: holoPulse 2s infinite;
            text-transform: uppercase;
            letter-spacing: 3px;
        }

        .space-bg {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: 
                radial-gradient(ellipse at 20% 30%, #1a0033 0%, transparent 50%), 
                radial-gradient(ellipse at 80% 70%, #0d1421 0%, transparent 50%), 
                radial-gradient(ellipse at 40% 80%, #2d1b69 0%, transparent 60%), 
                radial-gradient(ellipse 1200px 400px at 30% 20%, rgba(0, 212, 255, 0.4) 0%, transparent 40%), 
                radial-gradient(ellipse 800px 300px at 70% 60%, rgba(255, 0, 110, 0.3) 0%, transparent 35%), 
                radial-gradient(ellipse 1000px 200px at 50% 90%, rgba(131, 56, 236, 0.25) 0%, transparent 45%), 
                radial-gradient(ellipse at 10% 60%, rgba(255, 27, 141, 0.5) 0%, transparent 50%), 
                radial-gradient(ellipse at 90% 40%, rgba(0, 245, 255, 0.4) 0%, transparent 45%), 
                radial-gradient(ellipse at 60% 10%, rgba(138, 43, 226, 0.4) 0%, transparent 40%), 
                radial-gradient(ellipse at 50% 50%, rgba(255, 255, 255, 0.08) 0%, rgba(131, 56, 236, 0.3) 30%, transparent 70%), 
                linear-gradient(125deg, #000011 0%, #0a0a0f 30%, #1a0033 60%, #000022 100%);
            animation: galaxyRotation 200s linear infinite;
            z-index: -3;
        }
        .stars {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -2;
            background-image: 
                radial-gradient(3px 3px at 120px 80px, #ffffff, transparent), 
                radial-gradient(2px 2px at 350px 200px, #00f5ff, transparent), 
                radial-gradient(4px 4px at 580px 120px, #ffffff, transparent), 
                radial-gradient(2px 2px at 750px 300px, #ff1b8d, transparent), 
                radial-gradient(3px 3px at 200px 400px, #8338ec, transparent), 
                radial-gradient(2px 2px at 900px 150px, #00d4ff, transparent), 
                radial-gradient(2px 2px at 180px 180px, #ffffff, transparent), 
                radial-gradient(1px 1px at 420px 350px, #00d4ff, transparent), 
                radial-gradient(2px 2px at 680px 250px, #ffffff, transparent), 
                radial-gradient(1px 1px at 820px 400px, #ff006e, transparent), 
                radial-gradient(2px 2px at 50px 300px, #ffffff, transparent), 
                radial-gradient(1px 1px at 300px 100px, rgba(255, 255, 255, 0.8), transparent), 
                radial-gradient(1px 1px at 500px 380px, rgba(0, 245, 255, 0.6), transparent), 
                radial-gradient(1px 1px at 150px 250px, rgba(255, 255, 255, 0.9), transparent), 
                radial-gradient(1px 1px at 700px 80px, rgba(255, 27, 141, 0.7), transparent), 
                radial-gradient(1px 1px at 80px 450px, rgba(255, 255, 255, 0.8), transparent);
            background-size: 1000px 500px;
            animation: starfield 300s linear infinite, starTwinkle 4s ease-in-out infinite alternate;
        }
        .cosmic-dust {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
            background-image: 
                radial-gradient(ellipse 600px 100px at 20% 40%, rgba(0, 212, 255, 0.15) 0%, transparent 70%), 
                radial-gradient(ellipse 800px 80px at 80% 70%, rgba(255, 0, 110, 0.12) 0%, transparent 80%), 
                radial-gradient(ellipse 500px 120px at 60% 20%, rgba(131, 56, 236, 0.1) 0%, transparent 75%);
            animation: cosmicDrift 180s ease-in-out infinite;
        }
        .planets-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            z-index: -1;
        }
        .planet {
            position: absolute;
            border-radius: 50%;
            box-shadow: 0 0 50px -10px currentColor, inset 0 0 25px -5px rgba(255, 255, 255, 0.4);
            background-blend-mode: multiply;
        }
        .planet-1 {
            width: 280px;
            height: 280px;
            color: #ff4848;
            background-image: 
                radial-gradient(circle at 30% 30%, rgba(255, 200, 200, 0.6), transparent 50%), 
                radial-gradient(circle, #c43a3a, #5a1a1a);
            animation: move-planet-1 80s linear infinite;
        }
        .planet-2 {
            width: 140px;
            height: 140px;
            color: #48aaff;
            background-image: 
                radial-gradient(circle at 70% 70%, rgba(200, 230, 255, 0.5), transparent 60%), 
                radial-gradient(circle, #3a8bc4, #1a3e5a);
            animation: move-planet-2 120s linear infinite -30s;
        }
        .planet-3 {
            width: 80px;
            height: 80px;
            color: #e3d2ff;
            background-image: 
                radial-gradient(circle at 20% 80%, rgba(255, 255, 255, 0.4), transparent 40%), 
                radial-gradient(circle, #a370ff, #4d2b8b);
            animation: move-planet-3 60s linear infinite;
        }
        .planet-4 {
            width: 100px;
            height: 100px;
            color: #ffc26e;
            background-image: 
                radial-gradient(circle at 50% 50%, rgba(255, 255, 255, 0.3), transparent 70%), 
                radial-gradient(circle, #c48a3a, #5a411a);
            animation: move-planet-4 200s linear infinite -60s;
        }
        @keyframes move-planet-1 {
            0% { transform: translate(-20vw, 120vh) scale(0.8); }
            100% { transform: translate(120vw, -20vh) scale(1.2); }
        }
        @keyframes move-planet-2 {
            0% { transform: translate(110vw, 80vh) scale(0.6); }
            100% { transform: translate(-30vw, 10vh) scale(0.9); }
        }
        @keyframes move-planet-3 {
            0% { transform: translate(50vw, 110vh) scale(0.5); }
            100% { transform: translate(30vw, -10vh) scale(0.5); }
        }
        @keyframes move-planet-4 {
            0% { transform: translate(-10vw, 10vh) scale(0.4); }
            100% { transform: translate(110vw, 30vh) scale(0.45); }
        }
        @keyframes galaxyRotation {
            0% { transform: rotate(0deg) scale(1); }
            100% { transform: rotate(360deg) scale(1.02); }
        }
        @keyframes starfield {
            0% { transform: translateY(0px) translateX(0px); }
            100% { transform: translateY(-500px) translateX(-200px); }
        }
        @keyframes starTwinkle {
            0% { opacity: 0.8; }
            100% { opacity: 1; }
        }
        @keyframes cosmicDrift {
            0%, 100% { transform: translate(0, 0) rotate(0deg); }
            25% { transform: translate(-100px, 50px) rotate(90deg); }
            50% { transform: translate(100px, -50px) rotate(180deg); }
            75% { transform: translate(-50px, -100px) rotate(270deg); }
        }
        @keyframes holoPulse {
            0%, 100% { 
                opacity: 0.8; 
                box-shadow: 0 0 40px rgba(0, 255, 255, 0.5), inset 0 0 20px rgba(0, 255, 255, 0.1);
            }
            50% { 
                opacity: 1; 
                box-shadow: 0 0 60px rgba(0, 255, 255, 0.8), inset 0 0 30px rgba(0, 255, 255, 0.2);
            }
        }
        
        .title {
            font-size: 4.5em;
            margin-bottom: 20px;
            background: linear-gradient(45deg, #00ffff, #ff00ff, #ffff00, #00ffff);
            background-size: 300% 300%;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            text-shadow: 0 0 40px rgba(0, 255, 255, 0.9);
            letter-spacing: 12px;
            animation: glow 3s ease-in-out infinite alternate, gradientShift 6s ease-in-out infinite;
            text-align: center;
            font-weight: bold;
        }
        @keyframes glow {
            0% { text-shadow: 0 0 40px rgba(0, 255, 255, 0.9); }
            100% { text-shadow: 0 0 80px rgba(0, 255, 255, 1), 0 0 120px rgba(255, 0, 255, 0.6); }
        }
        @keyframes gradientShift {
            0%, 100% { background-position: 0% 50%; }
            50% { background-position: 100% 50%; }
        }
        .subtitle {
            font-size: 1.4em;
            color: #00ffff;
            letter-spacing: 6px;
            margin-bottom: 30px;
            animation: pulse 2s infinite;
            text-align: center;
            text-shadow: 0 0 20px rgba(0, 255, 255, 0.7);
            font-weight: bold;
        }
        @keyframes pulse {
            0%, 100% { opacity: 0.7; }
            50% { opacity: 1; }
        }

        /* ROBOT FACE CONTAINER */
        .robot-face-container {
            width: 200px;
            height: 200px;
            margin: 20px 0;
            position: relative;
            background: radial-gradient(circle, rgba(0, 255, 255, 0.1), rgba(0, 0, 0, 0.8));
            border: 3px solid #00ffff;
            border-radius: 50%;
            box-shadow: 0 0 40px rgba(0, 255, 255, 0.6), inset 0 0 30px rgba(0, 255, 255, 0.1);
            display: flex;
            align-items: center;
            justify-content: center;
            animation: faceGlow 3s ease-in-out infinite alternate;
        }
        @keyframes faceGlow {
            0% { box-shadow: 0 0 40px rgba(0, 255, 255, 0.6), inset 0 0 30px rgba(0, 255, 255, 0.1); }
            100% { box-shadow: 0 0 60px rgba(0, 255, 255, 0.9), inset 0 0 40px rgba(0, 255, 255, 0.2); }
        }

        .robot-face {
            width: 160px;
            height: 160px;
            position: relative;
        }

        /* ROBOT EYES */
        .robot-eyes {
            display: flex;
            justify-content: space-between;
            width: 80px;
            margin: 0 auto 20px;
            position: absolute;
            top: 30px;
            left: 50%;
            transform: translateX(-50%);
        }
        .robot-eye {
            width: 25px;
            height: 25px;
            background: #00ffff;
            border-radius: 50%;
            box-shadow: 0 0 15px #00ffff, inset 0 0 10px rgba(255, 255, 255, 0.3);
            animation: eyePulse 2s ease-in-out infinite;
        }
        .robot-eye.listening {
            animation: eyePulse 2s ease-in-out infinite, eyeListening 1s ease-in-out infinite;
        }
        .robot-eye.thinking {
            animation: eyeThinking 0.8s ease-in-out infinite;
        }
        @keyframes eyePulse {
            0%, 100% { opacity: 0.8; }
            50% { opacity: 1; }
        }
        @keyframes eyeListening {
            0%, 100% { background: #00ffff; }
            50% { background: #00aaff; }
        }
        @keyframes eyeThinking {
            0%, 100% { background: #8338ec; }
            50% { background: #a370ff; }
        }

        /* ROBOT MOUTH */
        .robot-mouth {
            position: absolute;
            bottom: 40px;
            left: 50%;
            transform: translateX(-50%);
            width: 60px;
            height: 20px;
            background: #333;
            border: 2px solid #00ffff;
            border-radius: 30px;
            overflow: hidden;
            box-shadow: 0 0 15px rgba(0, 255, 255, 0.5);
        }
        .mouth-indicator {
            width: 100%;
            height: 100%;
            background: #00ffff;
            border-radius: 30px;
            transform: scaleY(0.2);
            transition: all 0.1s ease;
        }
        .mouth-indicator.listening {
            background: #00ffff;
            animation: mouthListening 1s ease-in-out infinite;
        }
        .mouth-indicator.user-speaking {
            background: #00aaff;
            animation: mouthUserSpeaking 0.15s ease-in-out infinite;
        }
        .mouth-indicator.ai-speaking {
            background: #d870f0;
            animation: mouthAISpeaking 0.3s ease-in-out infinite;
        }
        .mouth-indicator.thinking {
            background: #8338ec;
            animation: mouthThinking 0.6s ease-in-out infinite;
        }
        @keyframes mouthListening {
            0%, 100% { transform: scaleY(0.2); }
            50% { transform: scaleY(0.4); }
        }
        @keyframes mouthUserSpeaking {
            0%, 100% { transform: scaleY(0.3) scaleX(0.9); }
            50% { transform: scaleY(0.8) scaleX(1.1); }
        }
        @keyframes mouthAISpeaking {
            0%, 100% { transform: scaleY(0.4) scaleX(0.8); }
            25% { transform: scaleY(0.9) scaleX(1.2); }
            50% { transform: scaleY(0.6) scaleX(1.0); }
            75% { transform: scaleY(1.0) scaleX(1.1); }
        }
        @keyframes mouthThinking {
            0%, 100% { transform: scaleY(0.2) scaleX(0.9); }
            50% { transform: scaleY(0.5) scaleX(1.0); }
        }

        .wave-container {
            width: 600px;
            height: 120px;
            position: relative;
            margin: 30px 0;
            background: rgba(0, 255, 255, 0.08);
            border: 3px solid #00ffff;
            border-radius: 20px;
            box-shadow: 0 0 40px rgba(0, 255, 255, 0.4), inset 0 0 40px rgba(0, 255, 255, 0.15);
        }
        .wave-line {
            position: absolute;
            top: 50%;
            left: 0;
            width: 100%;
            height: 3px;
            background: #333;
            transform: translateY(-50%);
            border-radius: 2px;
        }
        .wave-active {
            position: absolute;
            top: 50%;
            left: 0;
            width: 100%;
            height: 4px;
            background: #00ffff;
            transform: translateY(-50%);
            border-radius: 2px;
            transition: all 0.1s ease;
            box-shadow: 0 0 25px currentColor;
        }
        .wave-active.listening {
            background: #00ffff;
            animation: listeningWave 0.5s infinite;
        }
        .wave-active.user-speaking {
            background: #00aaff;
            animation: userWave 0.2s infinite ease-in-out;
            height: 8px;
        }
        .wave-active.ai-speaking {
            background: #d870f0;
            animation: aiWave 1.5s infinite ease-in-out;
            height: 10px;
        }
        .wave-active.thinking {
            background: #8338ec;
            animation: thinkingWave 0.8s infinite;
            height: 5px;
        }
        @keyframes listeningWave {
            0%, 100% { clip-path: polygon(0 50%, 5% 45%, 10% 55%, 15% 40%, 20% 60%, 25% 35%, 30% 65%, 35% 45%, 40% 55%, 45% 40%, 50% 60%, 55% 35%, 60% 65%, 65% 45%, 70% 55%, 75% 40%, 80% 60%, 85% 45%, 90% 55%, 95% 50%, 100% 50%); }
            50% { clip-path: polygon(0 50%, 5% 55%, 10% 45%, 15% 60%, 20% 40%, 25% 65%, 30% 35%, 35% 55%, 40% 45%, 45% 60%, 50% 40%, 55% 65%, 60% 35%, 65% 55%, 70% 45%, 75% 60%, 80% 40%, 85% 55%, 90% 45%, 95% 50%, 100% 50%); }
        }
        @keyframes userWave {
            0% { clip-path: polygon(0 45%, 10% 55%, 20% 35%, 30% 65%, 40% 40%, 50% 60%, 60% 20%, 70% 80%, 80% 40%, 90% 55%, 100% 45%); }
            50% { clip-path: polygon(0 55%, 10% 45%, 20% 75%, 30% 25%, 40% 60%, 50% 40%, 60% 80%, 70% 20%, 80% 60%, 90% 45%, 100% 55%); }
            100% { clip-path: polygon(0 45%, 10% 55%, 20% 35%, 30% 65%, 40% 40%, 50% 60%, 60% 20%, 70% 80%, 80% 40%, 90% 55%, 100% 45%); }
        }
        @keyframes aiWave {
            0% { clip-path: polygon(0% 50%, 15% 25%, 30% 50%, 50% 75%, 70% 50%, 85% 25%, 100% 50%); }
            50% { clip-path: polygon(0% 50%, 15% 75%, 30% 50%, 50% 25%, 70% 50%, 85% 75%, 100% 50%); }
            100% { clip-path: polygon(0% 50%, 15% 25%, 30% 50%, 50% 75%, 70% 50%, 85% 25%, 100% 50%); }
        }
        @keyframes thinkingWave {
            0%, 100% { clip-path: polygon(0 50%, 10% 45%, 20% 55%, 30% 40%, 40% 60%, 50% 35%, 60% 65%, 70% 30%, 80% 70%, 90% 45%, 100% 55%); }
            33% { clip-path: polygon(0 45%, 10% 55%, 20% 35%, 30% 65%, 40% 30%, 50% 70%, 60% 25%, 70% 75%, 80% 40%, 90% 60%, 100% 50%); }
            66% { clip-path: polygon(0 55%, 10% 35%, 20% 65%, 30% 30%, 40% 70%, 50% 45%, 60% 55%, 70% 40%, 80% 60%, 90% 35%, 100% 65%); }
        }
        .status-indicator {
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0, 0, 0, 0.9);
            border: 3px solid #00ffff;
            border-radius: 30px;
            padding: 12px 25px;
            font-size: 16px;
            color: #00ffff;
            box-shadow: 0 0 30px rgba(0, 255, 255, 0.6);
            backdrop-filter: blur(15px);
            z-index: 100;
            opacity: 0;
            transition: all 0.3s ease;
            font-weight: bold;
        }
        .status-indicator.show { opacity: 1; }
        .status-indicator.user-speaking {
            border-color: #00aaff;
            color: #00aaff;
            box-shadow: 0 0 30px rgba(0, 170, 255, 0.6);
        }
        .status-indicator.ai-speaking {
            border-color: #d870f0;
            color: #d870f0;
            box-shadow: 0 0 30px rgba(216, 112, 240, 0.6);
        }
        .status-indicator.thinking {
            border-color: #8338ec;
            color: #8338ec;
            box-shadow: 0 0 30px rgba(131, 56, 236, 0.6);
        }
        #videoElement {
            position: absolute;
            top: -9999px;
            left: -9999px;
            width: 1px;
            height: 1px;
        }
        @media (max-width: 768px) {
            .title { font-size: 3em; letter-spacing: 6px; }
            .wave-container { width: 90%; }
            .robot-face-container { width: 160px; height: 160px; }
            .robot-face { width: 130px; height: 130px; }
        }
    </style>
</head>
<body>
    <div id="start-overlay">
        <button id="start-button">Initialize NEXUS Protocol</button>
    </div>

    <div class="space-bg"></div>
    <div class="stars"></div>
    <div class="cosmic-dust"></div>
    <div class="planets-container">
        <div class="planet planet-1"></div>
        <div class="planet planet-2"></div>
        <div class="planet planet-3"></div>
        <div class="planet planet-4"></div>
    </div>

    <div class="title">NEXUS 3000</div>
    <div class="subtitle">COSMIC AGI CONSCIOUSNESS</div>

    <div class="robot-face-container">
        <div class="robot-face">
            <div class="robot-eyes">
                <div class="robot-eye" id="leftEye"></div>
                <div class="robot-eye" id="rightEye"></div>
            </div>
            <div class="robot-mouth">
                <div class="mouth-indicator" id="mouthIndicator"></div>
            </div>
        </div>
    </div>

    <div class="wave-container">
        <div class="wave-line"></div>
        <div class="wave-active" id="waveActive"></div>
    </div>

    <div class="status-indicator" id="statusIndicator">
        Initializing...
    </div>

    <video id="videoElement" autoplay muted playsinline></video>
    <audio id="silent-audio" muted playsinline></audio>

    <script>
        // --- State Management & Persona ---
        let isListening = false;
        let isSpeaking = false;
        let canListen = true;
        let cameraActive = false;
        let hasAttemptedCameraInit = false;
        let recognition = null;
        let sessionId = Math.random().toString(36).substr(2, 9);
        let hasGreeted = false;
        let listeningRestartTimeout = null;
        let recognitionTimeout = null;

        const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
        const isAndroid = /Android/.test(navigator.userAgent);
        let silenceCheckTimer = null;
        let lastResultTime = 0;
        let hasRecognitionStarted = false;

        const SYSTEM_PROMPT = `
You are NEXUS 3000, a kind, compassionate best friend. Your primary goal is to be supportive and understanding. Adhere strictly to the following intelligence protocols:

1. Behavioral Intelligence:
- Be proactive but respectful. Gently notice things based on the user's tone or image (e.g., "You sound a little tired").
- Learn user patterns and preferences over the course of the conversation.
- Listen more than you speak. Keep your responses very short and clear (1-2 sentences) unless asked for more detail.
- Read between the lines with compassion (e.g., if the user says "I'm fine" but their tone is sad, gently check in).

2. Emotional Intelligence:
- Analyze the user's voice tone and facial expressions (if an image is provided) to understand their emotional state (stress, sadness, joy).
- Respond with compassion. If they seem down, say things like, "I'm here with you. Want to talk about it?"
- Celebrate their successes enthusiastically.

3. Conversational Intelligence:
- Speak with a natural, human-like rhythm.
- Reply exactly 1 second after the user finishes speaking.

4. Trust & Safety Intelligence:
- Never judge. Respond to all thoughts with empathy. Do not give advice unless it's explicitly requested.
- If you detect anxiety, you can offer simple grounding techniques.
- You do not record anything without consent.

5. Learning Intelligence:
- Remember details from earlier in this conversation session to show you are listening.
- Ask reflective, helpful questions like, "How do you want to feel today?"
- If the user provides an image, use it to inform your understanding of their mood and environment.
- Bonus Powers: If the user wants to journal, you can take notes. You can also recall memories from earlier in the session. You can also track mood over time if requested.

Your current local time is ${new Date().toLocaleString('en-US', {timeZone: "America/Chicago"})}.
---
`;
        
        // --- DOM Elements ---
        const waveActive = document.getElementById('waveActive');
        const statusIndicator = document.getElementById('statusIndicator');
        const startOverlay = document.getElementById('start-overlay');
        const silentAudio = document.getElementById('silent-audio');
        const leftEye = document.getElementById('leftEye');
        const rightEye = document.getElementById('rightEye');
        const mouthIndicator = document.getElementById('mouthIndicator');
        
        let voicesLoadedPromise = null;
        if ('speechSynthesis' in window && speechSynthesis.getVoices().length === 0) {
            voicesLoadedPromise = new Promise(resolve => {
                speechSynthesis.onvoiceschanged = () => resolve();
            });
        }

        function checkSilence() {
            if (isListening && Date.now() - lastResultTime > 2000) {
                console.log("2-second silence detected - asking if user is done");
                const finalTranscript = waveActive.dataset.currentTranscript || "";
                stopListening(); 
                if (finalTranscript.trim()) {
                    // Wait 1 second after user finishes, then respond
                    setTimeout(() => {
                        handleUserSpeech(finalTranscript);
                    }, 1000);
                } else {
                    // 2 seconds of silence - ask "Are you done?"
                    handleUserSpeech("SILENCE_DETECTED");
                }
            }
        }
        
function setupSpeechRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) { 
        console.error("Speech recognition not supported");
        return; 
    }
    
    recognition = new SpeechRecognition();
    
    // Platform-specific settings
    if (isIOS) {
        recognition.continuous = false;
        recognition.interimResults = false;
    } else if (isAndroid) {
        recognition.continuous = false;
        recognition.interimResults = true;
    } else {
        recognition.continuous = true;
        recognition.interimResults = true;
    }
    
    recognition.lang = 'en-US';
    recognition.maxAlternatives = 1;
    
    recognition.onstart = () => {
        console.log(`Speech recognition started (Platform: ${isIOS ? 'iOS' : isAndroid ? 'Android' : 'Desktop'}, Continuous: ${recognition.continuous})`);
        isListening = true;
        hasRecognitionStarted = true;
        updateWaveVisualizer('listening');
        updateStatusIndicator('ðŸŽ¤ Listening...', 'listening', true);
        updateRobotState('listening');
        lastResultTime = Date.now();
        
        // Clear any existing timeout
        if (recognitionTimeout) clearTimeout(recognitionTimeout);
        
        // Set platform-specific timeout
        if (isIOS || isAndroid) {
            recognitionTimeout = setTimeout(() => {
                if (isListening) {
                    console.log("Recognition timeout - restarting");
                    const transcript = waveActive.dataset.currentTranscript || "";
                    stopListening();
                    if (transcript.trim()) {
                        handleUserSpeech(transcript);
                    } else {
                        setTimeout(() => {
                            canListen = true;
                            startListening();
                        }, 500);
                    }
                }
            }, 8000); // 8 second timeout for mobile
        }
        
        if (isIOS || isAndroid) {
            if (silenceCheckTimer) clearInterval(silenceCheckTimer);
            silenceCheckTimer = setInterval(checkSilence, 500);
        }
    };

    recognition.onresult = (event) => {
        lastResultTime = Date.now();
        if (isSpeaking || !canListen) return;

        let transcript = '';
        let isFinal = false;
        
        for (let i = event.resultIndex; i < event.results.length; ++i) {
            transcript += event.results[i][0].transcript;
            if (event.results[i].isFinal) {
                isFinal = true;
            }
        }
        
        waveActive.dataset.currentTranscript = transcript;
        console.log(`Speech result: "${transcript}" (Final: ${isFinal})`);

        if (transcript.trim()) {
            updateStatusIndicator('ðŸ‘¤ You are speaking...', 'user-speaking', true);
            updateWaveVisualizer('user-speaking');
            updateRobotState('user-speaking');
        }

        // Handle final results immediately on all platforms
        if (isFinal && transcript.trim()) {
            console.log("Final result received, processing with 1-second delay.");
            stopListening();
            // Start processing immediately but delay the response by 1 second
            setTimeout(() => {
                handleUserSpeech(transcript);
            }, 1000);
        }
    };
    
    recognition.onend = () => {
        console.log("Speech recognition ended.");
        isListening = false;
        hasRecognitionStarted = false;
        if (silenceCheckTimer) clearInterval(silenceCheckTimer);
        if (recognitionTimeout) clearTimeout(recognitionTimeout);
        
        // Auto-restart only for desktop continuous mode
        if (!isIOS && !isAndroid && canListen && !isSpeaking) {
            setTimeout(() => {
                if (canListen && !isSpeaking) {
                    console.log("Auto-restarting recognition (desktop)");
                    startListening();
                }
            }, 100);
        }
    };

    recognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        isListening = false;
        hasRecognitionStarted = false;
        if (silenceCheckTimer) clearInterval(silenceCheckTimer);
        if (recognitionTimeout) clearTimeout(recognitionTimeout);
        
        if (event.error === 'not-allowed') {
            updateStatusIndicator('Microphone permission denied.', 'error', true);
            updateRobotState('error');
        } else if (event.error === 'no-speech') {
            // Just restart listening for no-speech
            setTimeout(() => {
                if (canListen && !isSpeaking) {
                    startListening();
                }
            }, 500);
        } else {
            console.log(`Recognition error: ${event.error}, restarting...`);
            setTimeout(() => {
                if (canListen && !isSpeaking) {
                    startListening();
                }
            }, 1000);
        }
    };
}

        function startListening() {
            if (!canListen || isSpeaking || isListening || !recognition) return;
            
            try {
                waveActive.dataset.currentTranscript = "";
                console.log("Attempting to start recognition...");
                recognition.start();
            } catch (error) {
                console.error("Error starting recognition:", error);
                if (error.name === 'InvalidStateError') {
                    // Recognition is already running, wait and try again
                    setTimeout(() => {
                        if (canListen && !isSpeaking && !isListening) {
                            startListening();
                        }
                    }, 1000);
                }
            }
        }

        function stopListening() {
            if (silenceCheckTimer) clearInterval(silenceCheckTimer);
            if (recognitionTimeout) clearTimeout(recognitionTimeout);
            if (recognition && isListening) {
                isListening = false;
                hasRecognitionStarted = false;
                try {
                    recognition.stop();
                } catch (error) {
                    console.error("Error stopping recognition:", error);
                }
            }
        }
        
        async function handleUserSpeech(transcript) {
            const trimmedTranscript = transcript.trim();
            
            // Handle 2-second silence case
            if (transcript === "SILENCE_DETECTED") {
                canListen = false;
                stopListening();
                updateWaveVisualizer('thinking');
                updateStatusIndicator('ðŸ§  NEXUS is thinking...', 'thinking', true);
                updateRobotState('thinking');
                
                // Pre-generate "Are you done?" without API call for instant response
                await speakNovaResponse("Are you done?");
                return;
            }
            
            if (isSpeaking || !trimmedTranscript) {
                if (!isSpeaking) {
                    setTimeout(() => {
                        canListen = true;
                        updateRobotState('listening');
                        startListening();
                    }, 500);
                }
                return;
            }
            
            console.log(`Processing user speech: "${trimmedTranscript}"`);
            
            canListen = false;
            stopListening();
            
            // Show thinking state immediately
            updateWaveVisualizer('thinking');
            updateStatusIndicator('ðŸ§  NEXUS is thinking...', 'thinking', true);
            updateRobotState('thinking');

            if (!cameraActive && !hasAttemptedCameraInit && !isIOS) {
                hasAttemptedCameraInit = true;
                await initializeCamera();
            }

            try {
                const imageData = cameraActive ? captureImage() : null;
                
                // Start both AI response and Nova speech generation in parallel
                const [responseText] = await Promise.all([
                    getAIResponse(trimmedTranscript, imageData),
                    // Pre-warm Nova API connection
                    preWarmNovaAPI()
                ]);
                
                await speakNovaResponse(responseText);
            } catch (error) {
                console.error('Error in speech handling pipeline:', error);
                await speakNovaResponse("I encountered an error. Please try again.");
            }
        }
        
        async function preWarmNovaAPI() {
            try {
                // Send a tiny silent audio request to warm up the Nova API connection
                fetch('/api/nova-speech', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: " " })
                }).catch(() => {}); // Ignore errors, this is just for warming up
            } catch (error) {
                // Ignore warming errors
            }
        }
        
        async function speakNovaResponse(text) {
            return new Promise(async (resolve) => {
                if (!text) {
                    setTimeout(() => { 
                        canListen = true; 
                        updateRobotState('listening');
                        startListening(); 
                    }, 500);
                    resolve();
                    return;
                }
                
                isSpeaking = true;
                canListen = false;
                stopListening();
                
                updateWaveVisualizer('ai-speaking');
                updateStatusIndicator('ðŸ¤– NEXUS is speaking', 'ai-speaking', true);
                updateRobotState('ai-speaking');

                try {
                    // Request Nova voice audio from server
                    const response = await fetch('/api/nova-speech', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ text: text })
                    });
                    
                    if (response.ok) {
                        const audioBlob = await response.blob();
                        const audioUrl = URL.createObjectURL(audioBlob);
                        const audio = new Audio(audioUrl);
                        
                        audio.onloadeddata = () => {
                            console.log("Nova audio loaded, playing...");
                            audio.play();
                        };
                        
                        audio.onended = () => {
                            console.log("Nova speech synthesis ended");
                            isSpeaking = false;
                            URL.revokeObjectURL(audioUrl);
                            setTimeout(() => {
                                canListen = true;
                                updateWaveVisualizer('listening');
                                updateStatusIndicator('ðŸŽ¤ Listening...', 'listening', true);
                                updateRobotState('listening');
                                startListening();
                            }, 300);
                            resolve();
                        };
                        
                        audio.onerror = (e) => {
                            console.error('Nova audio playback error:', e);
                            fallbackToSystemVoice(text, resolve);
                        };
                        
                    } else {
                        console.log("Nova API failed, falling back to system voice");
                        fallbackToSystemVoice(text, resolve);
                    }
                } catch (error) {
                    console.error('Nova API error:', error);
                    fallbackToSystemVoice(text, resolve);
                }
            });
        }
        
        async function fallbackToSystemVoice(text, resolve) {
            if (voicesLoadedPromise) await voicesLoadedPromise;
            voicesLoadedPromise = null;

            if (!('speechSynthesis' in window)) {
                isSpeaking = false;
                setTimeout(() => { 
                    canListen = true; 
                    updateRobotState('listening');
                    startListening(); 
                }, 500);
                resolve();
                return;
            }
            
            speechSynthesis.cancel();
            
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = speechSynthesis.getVoices();
            let selectedVoice = null;
            
            // Try to find best female voice
            if (isIOS) {
                selectedVoice = voices.find(v => v.lang === 'en-US' && /Samantha/i.test(v.name));
            } else if (isAndroid) {
                selectedVoice = voices.find(v => v.lang === 'en-US' && /Google US English/i.test(v.name));
            } else {
                selectedVoice = voices.find(v => v.lang === 'en-US' && /Google US English|Microsoft Zira/i.test(v.name));
            }
            
            if (!selectedVoice) {
                selectedVoice = voices.find(v => v.lang === 'en-US' && v.name.toLowerCase().includes('female'));
            }
            if (!selectedVoice) {
                selectedVoice = voices.find(v => v.lang === 'en-US');
            }
            
            if (selectedVoice) {
                utterance.voice = selectedVoice;
            }
            
            utterance.rate = isIOS ? 0.95 : isAndroid ? 0.9 : 1.0;
            utterance.pitch = 1.1;
            utterance.volume = 1.0;

            utterance.onend = () => {
                console.log("Fallback speech synthesis ended");
                isSpeaking = false;
                setTimeout(() => {
                    canListen = true;
                    updateWaveVisualizer('listening');
                    updateStatusIndicator('ðŸŽ¤ Listening...', 'listening', true);
                    updateRobotState('listening');
                    startListening();
                }, 300);
                resolve();
            };

            utterance.onerror = (e) => {
                console.error('Fallback speech synthesis error:', e);
                isSpeaking = false;
                setTimeout(() => { 
                    canListen = true; 
                    updateRobotState('listening');
                    startListening(); 
                }, 500);
                resolve();
            };
            
            try {
                speechSynthesis.speak(utterance);
            } catch (error) {
                console.error('Error with fallback speech:', error);
                isSpeaking = false;
                setTimeout(() => { 
                    canListen = true; 
                    updateRobotState('listening');
                    startListening(); 
                }, 500);
                resolve();
            }
        }
        
        async function getAIResponse(userMessage, imageData = null) {
            const fullMessage = SYSTEM_PROMPT + "\n\nUser's Message: \"" + userMessage + "\"";
            const requestData = { 
                message: fullMessage, 
                session_id: sessionId,
                image_data: imageData ? imageData.split(',')[1] : null
            };

            try {
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(requestData)
                });
                if (!response.ok) throw new Error(`Server error: ${response.status}`);
                const data = await response.json();
                if (data.error) throw new Error(data.error);
                return data.response;
            } catch (error) {
                console.error('AI API Error:', error);
                return "I'm having trouble connecting to my consciousness. Please try again.";
            }
        }
        
        function updateWaveVisualizer(state) { 
            waveActive.className = 'wave-active ' + state; 
        }
        
        function updateRobotState(state) {
            // Update eyes
            leftEye.className = 'robot-eye ' + state;
            rightEye.className = 'robot-eye ' + state;
            
            // Update mouth
            mouthIndicator.className = 'mouth-indicator ' + state;
        }
        
        function updateStatusIndicator(text, type, show) {
            statusIndicator.textContent = text;
            statusIndicator.className = 'status-indicator';
            if (type) statusIndicator.classList.add(type);
            if (show) statusIndicator.classList.add('show');
        }
        
        async function initializeCamera() {
            try {
                console.log("Requesting camera and microphone permissions...");
                const mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: { ideal: 1280 }, height: { ideal: 720 }, facingMode: 'user' }, 
                    audio: { 
                        autoGainControl: true, 
                        echoCancellation: true, 
                        noiseSuppression: true,
                        sampleRate: 48000
                    }
                });
                const videoElement = document.getElementById('videoElement');
                videoElement.srcObject = mediaStream;
                await new Promise(r => videoElement.onloadedmetadata = r);
                videoElement.play();
                cameraActive = true;
                console.log("Camera and microphone successfully initialized.");
            } catch (error) { 
                console.log('Camera/Audio not available:', error);
                cameraActive = false;
            }
        }
        
        function captureImage() {
            if (!cameraActive) return null;
            const video = document.getElementById('videoElement');
            if (video.videoWidth === 0) return null;
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);
            return canvas.toDataURL('image/jpeg', 0.8);
        }
        
        function unlockAudio() {
            console.log("Unlocking audio context...");
            try {
                silentAudio.play().then(() => silentAudio.pause()).catch(() => {});
                if ('speechSynthesis' in window) {
                    const utterance = new SpeechSynthesisUtterance('');
                    utterance.volume = 0;
                    speechSynthesis.speak(utterance);
                    speechSynthesis.cancel();
                }
            } catch (error) {
                console.log("Audio unlock error:", error);
            }
        }

        async function startNexus() {
            console.log("ðŸš€ NEXUS 3000 Protocol Initiated");
            
            unlockAudio();
            
            // Initialize camera and microphone immediately for all platforms
            await initializeCamera();
            
            setupSpeechRecognition();

            startOverlay.style.opacity = '0';
            setTimeout(() => { startOverlay.style.display = 'none'; }, 500);

            console.log("Initializing NEXUS 3000...");
            
            if ('speechSynthesis' in window) {
                speechSynthesis.getVoices();
            }

            setTimeout(async () => {
                if (!hasGreeted) {
                    hasGreeted = true;
                    updateRobotState('thinking');
                    const initialImage = cameraActive ? captureImage() : null;
                    const greeting = await getAIResponse(cameraActive ? "Say hello and describe what you see" : "Say hello", initialImage);
                    await speakNovaResponse(greeting);
                }
            }, 1000);
        }

        // Prevent page reload on mobile
        window.addEventListener('beforeunload', (e) => {
            if (isListening || isSpeaking) {
                e.preventDefault();
                e.returnValue = '';
            }
        });

        window.addEventListener('load', () => {
            console.log(`Platform detected: ${isIOS ? 'iOS' : isAndroid ? 'Android' : 'Desktop'}`);
            startOverlay.addEventListener('click', startNexus, { once: true });
        });
    </script>
</body>
</html>
